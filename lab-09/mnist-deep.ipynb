{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 100]))\n",
    "b1 = tf.Variable(tf.random_normal([100]))\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([100, 100]))\n",
    "b2 = tf.Variable(tf.random_normal([100]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([100, 100]))\n",
    "b3 = tf.Variable(tf.random_normal([100]))\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([100, nb_classes]))\n",
    "b4 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer3, W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.650159491\n",
      "Epoch: 0002 cost = 0.914586164\n",
      "Epoch: 0003 cost = 0.731060020\n",
      "Epoch: 0004 cost = 0.628772640\n",
      "Epoch: 0005 cost = 0.560330145\n",
      "Epoch: 0006 cost = 0.510743208\n",
      "Epoch: 0007 cost = 0.472506091\n",
      "Epoch: 0008 cost = 0.441677984\n",
      "Epoch: 0009 cost = 0.415976437\n",
      "Epoch: 0010 cost = 0.394489129\n",
      "Epoch: 0011 cost = 0.375600418\n",
      "Epoch: 0012 cost = 0.358925614\n",
      "Epoch: 0013 cost = 0.343874336\n",
      "Epoch: 0014 cost = 0.331408443\n",
      "Epoch: 0015 cost = 0.319053202\n",
      "Accuracy: 0.8923\n",
      "Label:  [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADL5JREFUeJzt3W+oXPWdx/HPJ7YlaPpAzWwIqfZ2gxRE3HQzBCEilW6LlUJSEGkelFsJm0AqbjAPNnGR9YHIRWJDQamk6yVp7aYVWkkeaBsbaqSwFK/i+qe2GsMNSYjJvVipRaGr+e6Deyy3eufMOOfMnMn9vl9wuTPne86cL0M++c2c39z5OSIEIJ8lTTcAoBmEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUp8a5smWL18eY2NjwzwlkMr09LRmZ2fdy76Vwm/7Jknfl3SRpP+KiImy/cfGxjQ1NVXllABKtNvtnvft+2W/7YskPSTp65KulrTJ9tX9Ph6A4arynn+dpGMRcTwi/irpp5I21NMWgEGrEv5Vkk7Ou3+q2PZ3bG+xPWV7amZmpsLpANRp4Ff7I2JvRLQjot1qtQZ9OgA9qhL+05KumHf/c8U2ABeAKuF/VtJVtr9g+zOSviXpUD1tARi0vqf6IuJ927dL+pXmpvomI+KV2joDMFCV5vkj4glJT9TUC4Ah4uO9QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyQ11CW6gU9iYqJ00Wft2rWrtH706NGOtRtuuKGvnhYTRn4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrSPL/taUnvSPpA0vsR0a6jKUCSbJfWlywpH7see+yxjjXm+ev5kM+NETFbw+MAGCJe9gNJVQ1/SDps+znbW+poCMBwVH3Zf31EnLb9D5Kesv2HiHhm/g7FfwpbJOnKK6+seDoAdak08kfE6eL3OUmPS1q3wD57I6IdEe1Wq1XldABq1Hf4bV9i+7Mf3pb0NUkv19UYgMGq8rJ/haTHi+mYT0n674j4ZS1dARi4vsMfEccl/VONvSCZEydOlNYffvjhSo9/5513Vjp+sWOqD0iK8ANJEX4gKcIPJEX4gaQIP5AUX92NgXr77bc71jZu3Fh67MmTJyud++KLL650/GLHyA8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHPj0Xr3nvv7Vh78MEHh9jJaGLkB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkmOdHJbOz5Qs0r1+/vmPt2LFjlc7dbZnt3bt3V3r8xY6RH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS6jrPb3tS0jcknYuIa4ptl0n6maQxSdOSbo2IPw2uTYyqAwcOlNbfeOONjjXblc795JNPltaXLl1a6fEXu15G/n2SbvrItp2SjkTEVZKOFPcBXEC6hj8inpH01kc2b5C0v7i9X1L50isARk6/7/lXRMSZ4vabklbU1A+AIal8wS8iQlJ0qtveYnvK9tTMzEzV0wGoSb/hP2t7pSQVv8912jEi9kZEOyLarVarz9MBqFu/4T8kaby4PS7pYD3tABiWruG3fUDS/0j6ou1TtjdLmpD0VduvS/qX4j6AC0jXef6I2NSh9JWae8EI2rdvX2l9587+Z3mvvfba0vr27dtL68zjV8Mn/ICkCD+QFOEHkiL8QFKEH0iK8ANJ8dXdi9z58+dL64cOHSqtb968ubTe7c9yy6bjJicnS49ds2ZNaR3VMPIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFLM8y9y3ebxb7nlloGe/8Ybb+xYYx6/WYz8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU8/yL3OHDh0vrc6utddbt+wC2bdtWWn/ooYdK62gOIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNV1nt/2pKRvSDoXEdcU2+6R9K+SZord7oqIJwbVJMqdPHmyY+3RRx8tPbbb9+4vWVI+Pqxdu7a0jtHVy8i/T9JNC2zfExFrih+CD1xguoY/Ip6R9NYQegEwRFXe899u+0Xbk7Yvra0jAEPRb/h/IGm1pDWSzkh6oNOOtrfYnrI9NTMz02k3AEPWV/gj4mxEfBAR5yX9UNK6kn33RkQ7ItqtVqvfPgHUrK/w21457+43Jb1cTzsAhqWXqb4Dkr4sabntU5L+U9KXba+RFJKmJW0dYI8ABqBr+CNi0wKbHxlAL+jgvffeK63ffffdHWvvvvtupXM/8EDHyzmSpPHx8UqPj+bwCT8gKcIPJEX4gaQIP5AU4QeSIvxAUnx19wXg6aefLq13+7PdKrZv3z6wx0azGPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnm+UfAxMREaf3+++8f2Llvu+22gT02RhsjP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTz/ELz22mul9V27dpXWuy2TXeaOO+4ore/Zs6fvx8aFjZEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5LqOs9v+wpJP5K0QlJI2hsR37d9maSfSRqTNC3p1oj40+BaHV3Hjx8vrd93332l9W7z+KtXry6tb926tWOt2zw/8upl5H9f0o6IuFrSdZK+a/tqSTslHYmIqyQdKe4DuEB0DX9EnImI54vb70h6VdIqSRsk7S922y9p46CaBFC/T/Se3/aYpC9J+p2kFRFxpii9qbm3BQAuED2H3/YyST+XtD0i/jy/FhGhuesBCx23xfaU7amZmZlKzQKoT0/ht/1pzQX/JxHxi2LzWdsri/pKSecWOjYi9kZEOyLarVarjp4B1KBr+G1b0iOSXo2I780rHZI0Xtwel3Sw/vYADEovf9K7XtK3Jb1k+4Vi212SJiQ9ZnuzpBOSbh1Mi6Nv9+7dpfWqS2iXTeVJ0o4dOyo9PnLqGv6I+K0kdyh/pd52AAwLn/ADkiL8QFKEH0iK8ANJEX4gKcIPJMVXd/dodna2Y+3w4cOlx15++eWl9YMHyz8ftXbt2tI60A9GfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iinn+Hi1durRjbdWqVaXHbtu2rbR+3XXX9dUTUAUjP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTx/j5YtW9axdvTo0SF2AtSDkR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkuoafttX2P6N7d/bfsX2vxXb77F92vYLxc/Ng28XQF16+ZDP+5J2RMTztj8r6TnbTxW1PRGxe3DtARiUruGPiDOSzhS337H9qqTyr64BMPI+0Xt+22OSviTpd8Wm222/aHvS9qUdjtlie8r21MzMTKVmAdSn5/DbXibp55K2R8SfJf1A0mpJazT3yuCBhY6LiL0R0Y6IdqvVqqFlAHXoKfy2P6254P8kIn4hSRFxNiI+iIjzkn4oad3g2gRQt16u9lvSI5JejYjvzdu+ct5u35T0cv3tARiUXq72r5f0bUkv2X6h2HaXpE2210gKSdOStg6kQwAD0cvV/t9K8gKlJ+pvB8Cw8Ak/ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUo6I4Z3MnpF0Yt6m5ZJmh9bAJzOqvY1qXxK99avO3j4fET19X95Qw/+xk9tTEdFurIESo9rbqPYl0Vu/muqNl/1AUoQfSKrp8O9t+PxlRrW3Ue1Lord+NdJbo+/5ATSn6ZEfQEMaCb/tm2z/0fYx2zub6KET29O2XypWHp5quJdJ2+dsvzxv22W2n7L9evF7wWXSGuptJFZuLllZutHnbtRWvB76y37bF0l6TdJXJZ2S9KykTRHx+6E20oHtaUntiGh8Ttj2DZL+IulHEXFNse1+SW9FxETxH+elEfHvI9LbPZL+0vTKzcWCMivnrywtaaOk76jB566kr1vVwPPWxMi/TtKxiDgeEX+V9FNJGxroY+RFxDOS3vrI5g2S9he392vuH8/QdehtJETEmYh4vrj9jqQPV5Zu9Lkr6asRTYR/laST8+6f0mgt+R2SDtt+zvaWpptZwIpi2XRJelPSiiabWUDXlZuH6SMrS4/Mc9fPitd144Lfx10fEf8s6euSvlu8vB1JMfeebZSma3pauXlYFlhZ+m+afO76XfG6bk2E/7SkK+bd/1yxbSRExOni9zlJj2v0Vh8+++EiqcXvcw338zejtHLzQitLawSeu1Fa8bqJ8D8r6SrbX7D9GUnfknSogT4+xvYlxYUY2b5E0tc0eqsPH5I0Xtwel3SwwV7+zqis3NxpZWk1/NyN3IrXETH0H0k3a+6K/xuS/qOJHjr09Y+S/rf4eaXp3iQd0NzLwP/T3LWRzZIul3RE0uuSfi3pshHq7ceSXpL0ouaCtrKh3q7X3Ev6FyW9UPzc3PRzV9JXI88bn/ADkuKCH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpP4fZg3ndBRsQfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "        print('Epoch: {:04d} cost = {:.9f}'.format((epoch + 1), avg_cost))\n",
    "    print(\"Accuracy:\", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r : r + 1]}))\n",
    "\n",
    "    plt.imshow(mnist.test.images[r : r + 1].reshape(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note\n",
    "```\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer3, W4) + b4)\n",
    "```\n",
    "위 코드를 처음에 \n",
    "```\n",
    "layer4 = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "hypothesis = tf.nn.softmax(layer4)\n",
    "```\n",
    "로 코딩했었는데 확률이 너무 이상하게 나와서 뭐가 잘못된 것 같았다.\n",
    "\n",
    "생각해보니 100개로 들어온 input을 10개로 줄이는 과정에서 값들간의 차이가 커야 구분하기가 유리해지는데 sigmoid를 하여 벌어진 값들을 다시 0과 1사이의 값으로 모았으니 그런 문제가 생긴 것이 당연했다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
